{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T07:38:39.460426Z",
     "start_time": "2023-11-20T07:38:39.453691Z"
    }
   },
   "id": "7f32de6e75938fd6"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 28, 28, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 2048)              6424576   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 62)                127038    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6605310 (25.20 MB)\n",
      "Trainable params: 6605310 (25.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 89.5369 - accuracy: 0.0340 - val_loss: 5.1884 - val_accuracy: 0.0439\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 3.8951 - accuracy: 0.0566 - val_loss: 4.0701 - val_accuracy: 0.0175\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 3.6516 - accuracy: 0.0566 - val_loss: 4.1513 - val_accuracy: 0.0439\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.6007 - accuracy: 0.0792 - val_loss: 4.2371 - val_accuracy: 0.0439\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.5806 - accuracy: 0.0755 - val_loss: 4.7091 - val_accuracy: 0.0175\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.5815 - accuracy: 0.0604 - val_loss: 4.1230 - val_accuracy: 0.0439\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.6123 - accuracy: 0.0792 - val_loss: 4.2193 - val_accuracy: 0.0439\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.5694 - accuracy: 0.0792 - val_loss: 4.3089 - val_accuracy: 0.0439\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.5776 - accuracy: 0.0792 - val_loss: 4.3238 - val_accuracy: 0.0439\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.5690 - accuracy: 0.0792 - val_loss: 4.3236 - val_accuracy: 0.0439\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x14dbc5730>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "X_SHAPE = [128, 128, 3]\n",
    "Y_SHAPE = [62]\n",
    "\n",
    "def load_images_and_labels_from_partition_file(file_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            image_path = line.strip()\n",
    "            label = os.path.basename(os.path.dirname(image_path))  # Extract label from the last directory\n",
    "            label = int(label)  # Convert label to an integer\n",
    "            \n",
    "            image = Image.open(\"/Users/janezbozic/faks/Magistrska/fl-testbed/code/examples/femnist_example/\" + image_path)\n",
    "            image = image.resize((IMAGE_SIZE, IMAGE_SIZE))  # Resize if needed\n",
    "            image_array = np.array(image) / 255.0  # Normalize pixel values\n",
    "            \n",
    "            images.append(image_array)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Specify the paths to your train and test files\n",
    "train_file_path = '/Users/janezbozic/faks/Magistrska/fl-testbed/code/examples/femnist_example/data/partition_0_train.txt'\n",
    "test_file_path = '/Users/janezbozic/faks/Magistrska/fl-testbed/code/examples/femnist_example/data/partition_0_test.txt'\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_images, train_labels = load_images_and_labels_from_partition_file(train_file_path)\n",
    "train_labels_onehot = tf.keras.utils.to_categorical(train_labels, num_classes=62)\n",
    "\n",
    "# Load and preprocess testing data\n",
    "test_images, test_labels = load_images_and_labels_from_partition_file(test_file_path)\n",
    "test_labels_onehot = tf.keras.utils.to_categorical(test_labels, num_classes=62)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=tuple(X_SHAPE)),\n",
    "            tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(2048, activation='relu'),\n",
    "            tf.keras.layers.Dense(62, activation=\"softmax\"),\n",
    "        ])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels_onehot, epochs=10, validation_data=(test_images, test_labels_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T07:47:19.574687Z",
     "start_time": "2023-11-20T07:47:15.968173Z"
    }
   },
   "id": "312d54086ecfd693"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cd0d9d1a6010793c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
